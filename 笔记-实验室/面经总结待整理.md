#### C++

- DLL地狱问题是什么 遇到过么  什么原因导致 

  https://blog.csdn.net/qwertyupoiuytr/article/details/53999586、

  DLL地狱问是[归根结底](https://www.baidu.com/s?wd=%E5%BD%92%E6%A0%B9%E7%BB%93%E5%BA%95&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)是因为DLL当初是作为函数级共享库设计的，并不能真正提供一个类所必需的信息

  

- linux 文件系统的结构

![img](https://images2017.cnblogs.com/blog/1138116/201708/1138116-20170816201110834-1885845398.png)

- socket clsoe 是否从epoll set 中删除

  只要这个socket没有被dup fcntl fork等函数拷贝，就会自动删除。言外之意就是，当close是真的释放了文件描述符资源，而不是减少文件描述的引用计数的话，就会自动从epoll set 中删除

- mallco 的原理细节

  ![img](https://img-my.csdn.net/uploads/201207/22/1342931565_1627.png)

为什么需要虚拟内存？

CPU是和寄存器打交道的，但寄存器的容量毕竟有限，因此就需要高速缓存存储器来作为寄存器的缓存，当有些数据在寄存器中找不到时，CPU就可以去寻找高速缓存这个存储器中的内容，如果告诉缓存器还没有这个数据，那我就去主存中再去寻找这个数据，如果主存中也还没有，那就去磁盘中找吧

**虚拟内存就是去解决主存到磁盘这个层次的方案**。

如果不使用虚拟地址使用物理地址会产生如下的问题：

- 进程地址空间不隔离，没有权限保护
- 内存使用效率低
- 程序运行的地址不确定

个人的理解就是：使用虚拟内存其实就没有必要一次将程序全部装入内存 这样可以动态的去根据情况装载 可以最大化的利用内存，其次就是使用了虚拟内存，进程之间的隔离就很好，程序之间就不会直接访问物理内可以有效的保护。

缓存颠簸是什么现象？

磁盘和主存传送页的活动叫做页面调度。页面调度会引起磁盘流量，如果程序的局部性不好，会频繁进行页面调度，叫做“缓存颠簸”



Linux把虚拟内存划分成区域area的集合，一个area包括连续的多个页

内核为每个进程维护了一个单独的任务结果task_struct

task_struct的mm指针，指向了mm_struct，该结构描述虚拟内存的运行状态。

mm_struct的pgd指针指向进程的一级页表的基地址。

vm_area_struct描述area的结构，vm_start表示area的开始位置，vm_end表示area的结束位置，vm_prot表示area内的页的读写权限，vm_flags表示area内的页面是进程私有还是共享，vm_next指向下一个area节点



![img](https://images2015.cnblogs.com/blog/300946/201606/300946-20160623171927344-1692955841.png)





- 虚拟文件系统

  

![img](https://images0.cnblogs.com/blog2015/710103/201504/231651108438201.jpg)

Linux正统的文件系统(如ext2、ext3)一个文件由目录项、inode和数据块组成。

目录项:包括文件名和inode节点号。
Inode：又称文件索引节点，是文件基本信息的存放地和数据块指针存放地。
数据块：文件的具体内容存放地。



Inode包含文件的属性(如读写属性、owner等，以及指向数据块的指针)，数据区域块则是文件内容。

当查看某个文件时，会先从inode table中查出文件属性及数据存放点，再从数据块中读取数据。

![img](https://images0.cnblogs.com/blog2015/710103/201504/231652466564730.png)

目录项结构就是 文件名 和inode结点的映射关系

文件的内容和属性是分开存放的



它将磁盘块分为以下三个部分：
1)        超级块，文件系统中第一个块被称为超级块。这个块存放文件系统本身的结构信息。比如，超级块记录了每个区域的大小，超级块也存放未被使用的磁盘块的信息。
2)        I-切点表。超级块的下一个部分就是i-节点表。每个i-节点就是一个对应一个文件/目录的结构，这个结构它包含了一个文件的长度、创建及修改时间、权限、所属关系、磁盘中的位置等信息。一个文件系统维护了一个索引节点的数组，每个文件或目录都与索引节点数组中的唯一一个元素对应。系统给每个索引节点分配了一个号码，也就是该节点在数组中的索引号，称为索引节点号
3)        数据区。文件系统的第3个部分是数据区。文件的内容保存在这个区域。磁盘上所有块的大小都一样。如果文件包含了超过一个块的内容，则文件内容会存放在多个磁盘块中。一个较大的文件很容易分布上千个独产的磁盘块中。



创建成功一个文件主要有以下四个步骤：
1)        存储属性 也就是文件属性的存储，内核先找到一块空的i-节点。例如，内核找到i-节点号921130。内核把文件的信息记录其中。如文件的大小、文件所有者、和创建时间等。
2)        存储数据 即文件内容的存储，由于该文件需要3个数据块。因此内核从自由块的列表中找到3个自由块。如600、200、992，内核缓冲区的第一块数据复制到块600，第二和第三分别复制到922和600.
3)        记录分配情况，数据保存到了三个数据块中。所以必须要记录起来，以后再找到正确的数据。分配情况记录在文件的i-节点中的磁盘序号列表里。这3个编号分别放在最开始的3个位置。
4)        添加文件名到目录，新文件的名字是userlist 内核将文件的入口(47,userlist)添加到目录文件里。文件名和i-节点号之间的对应关系将文件名和文件和文件的内容属性连接起来，找到文件名就找到文件的i-节点号，通过i-节点号就能找到文件的属性和内容。





文件必然归属于某一个目录 当创建文件之后，会在目录文件当中 将该文件的文件名和i节点的对应关系 连接起来 这样查看该目录的时候 就能够看到有哪些文件 通过文件名就可以 获取i节点  通过i结点可以获取 文件的属性信息 以及文件数据块所在的位置 从而读入文件内容。



在 Linux 中，元数据中的 inode 号（inode 是文件元数据的一部分但其并不包含文件名，inode 号即索引节点号）才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过 inode 号寻找正确的文件数据块

![img](https://images0.cnblogs.com/blog2015/710103/201504/231658056407577.png)

node包含文件的元信息，具体来说有以下内容：
*文件的字节数
*文件拥有者的UserID*文件的GroupID
*文件的读、写、执行权限
*文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。
*链接数，即有多少文件名指向这个inode*文件数据block的位置可以用stat命令，查看某个文件的inode信息

```c
struct inode {
        struct hlist_node       i_hash;              /* 哈希表 */
        struct list_head        i_list;              /* 索引节点链表 */
        struct list_head        i_dentry;            /* 目录项链表 */
        unsigned long           i_ino;               /* 节点号 */
        atomic_t                i_count;             /* 引用记数 */
        umode_t                 i_mode;              /* 访问权限控制 */
        unsigned int            i_nlink;             /* 硬链接数 */
        uid_t                   i_uid;               /* 使用者id */
        gid_t                   i_gid;               /* 使用者id组 */
        kdev_t                  i_rdev;              /* 实设备标识符 */
        loff_t                  i_size;              /* 以字节为单位的文件大小 */
        struct timespec         i_atime;             /* 最后访问时间 */
        struct timespec         i_mtime;             /* 最后修改(modify)时间 */
        struct timespec         i_ctime;             /* 最后改变(change)时间 */
        unsigned int            i_blkbits;           /* 以位为单位的块大小 */
        unsigned long           i_blksize;           /* 以字节为单位的块大小 */
        unsigned long           i_version;           /* 版本号 */
        unsigned long           i_blocks;            /* 文件的块数 */
        unsigned short          i_bytes;             /* 使用的字节数 */
        spinlock_t              i_lock;              /* 自旋锁 */
        struct rw_semaphore     i_alloc_sem;         /* 索引节点信号量 */
        struct inode_operations *i_op;               /* 索引节点操作表 */
        struct file_operations  *i_fop;              /* 默认的索引节点操作 */
        struct super_block      *i_sb;               /* 相关的超级块 */
        struct file_lock        *i_flock;            /* 文件锁链表 */
        struct address_space    *i_mapping;          /* 相关的地址映射 */
        struct address_space    i_data;              /* 设备地址映射 */
        struct dquot            *i_dquot[MAXQUOTAS]; /* 节点的磁盘限额 */
        struct list_head        i_devices;           /* 块设备链表 */
        struct pipe_inode_info  *i_pipe;             /* 管道信息 */
        struct block_device     *i_bdev;             /* 块设备驱动 */
        unsigned long           i_dnotify_mask;      /* 目录通知掩码 */
        struct dnotify_struct   *i_dnotify;          /* 目录通知 */
        unsigned long           i_state;             /* 状态标志 */
        unsigned long           dirtied_when;        /* 首次修改时间 */
        unsigned int            i_flags;             /* 文件系统标志 */
        unsigned char           i_sock;              /* 可能是个套接字吧 */
        atomic_t                i_writecount;        /* 写者记数 */
        void                    *i_security;         /* 安全模块 */
        __u32                   i_generation;        /* 索引节点版本号 */
        union {
                void            *generic_ip;         /* 文件特殊信息 */
        } u;
};
```

文件系统如何存取文件的：
     1)、根据文件名，通过Directory里的对应关系，找到文件对应的Inodenumber

​     2)、再根据Inodenumber读取到文件的Inodetable
​     3)、再根据Inodetable中的Pointer读取到相应的Blocks



inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。



每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。

由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。





- **硬链接**

  **Unix/Linux系统允许，多个文件名指向同一个inode号码。**

**这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为"硬链接"（hard link）。**

硬连接也是文件。其类型是普通文件。

**反过来，删除一个文件名，就会使得inode节点中的"链接数"减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。**



文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的"软链接"（soft link）或者"符号链接（symbolic link）。



- **inode的特殊作用**

  有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。

  移动文件或重命名文件，只是改变文件名，不影响inode号码。 所以移动是非常的快的？

  打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。



查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令：df -i



　在一台配置较低的Linux服务器(内存、硬盘比较小)的/data分区内创建文件时，系统提示磁盘空间不足，用df -h命令查看了一下磁盘使用情况，发现/data分区只使用了66%，还有12G的剩余空间，按理说不会出现这种问题。 后来用df -i查看了一下/data分区的索引节点(inode)，发现已经用满(IUsed=100%)，导致系统无法创建新目录和文件。



也就是说目录项当中包含的是 文件名和inode结点的映射表，一直存在于内存当中。

目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。



1.-，普通文件。

2.d，目录文件，d是directory的简写。

3.l，软连接文件，亦称符号链接文件，s是soft或者symbolic的简写。

4.b，块文件，是设备文件的一种（还有另一种），b是block的简写。

5.c，字符文件，也是设备文件的一种（这就是第二种），c是character的文件。

某文件的父目录会（记录）知道该文件的inode号

目录文件就是一张表，存储了它内部有哪些文件名，以及该文件名对应的inode号

目录文件：存储了一张表，该表就是该目录文件下，所有文件名和inode的映射关系。

为什么同一个文件系统移动文件要比跨文件系统快？

答：因为只需要修改某个目录中路径和inode对应关系即可，不需要重新写一遍数据域。





Linux为每一个目录建立一个目录项结构，而且也为每个文件建立一个目录项结构。

目录项结构中包含很多信息：可以建立目录、子目录、文件之间的关系，利用目录项关系，加快文件的查找。

因此linux引入目录项的概念主要是出于方便查找文件的目的

目录项对象没有对应的磁盘数据，所以在Dentry中不包含“脏”域。

VFS在遍历路径名的过程中现场将它们逐个地解析成目录项对象。为了加快文件的查找，每一个曾被读取的目录或文件都可能在目录高速缓存（directory cache）中。



都会被缓存！为什么  减少IO 次数！！

Linux为了提高目录项对象的处理效率，设计与实现了目录项高速缓存（dentry cache，简称dcache），它主要由两个数据结构组成

哈希链表dentry_hashtable：dcache中的所有dentry对象都通过d_hash指针域链到相应的dentry哈希链表中。





- 挂载

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20180216152344159?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYWJjXzEyMzY2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

**1. 挂载点必须是一个目录** 
**2. 一个分区挂载在一个已存在的目录上，这个目录可以不为空，但挂载后这个目录下以前的内容将不可用；对于其他操作系统建立的文件系统的挂载也是这样** 
**挂载前要了解linux是否支持所要挂载的文件系统格式**



**inux挂载使用mount命令：** 
**mount [-参数] [设备名] [挂载点]**

而这里要使用到的挂载技术，就是 Linux 的**绑定挂载（bind mount）机制**。它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。

其实，如果你了解 Linux 内核的话，就会明白，绑定挂载实际上是一个 inode 替换的过程。在 Linux 操作系统中，inode 可以理解为存放文件内容的“对象”，而 dentry，也叫目录项，就是访问这个 inode 所使用的“指针”。

![img](https://static001.geekbang.org/resource/image/95/c6/95c957b3c2813bb70eb784b8d1daedc6.png)









- 对于信号的处理

![img](https://images2015.cnblogs.com/blog/899685/201701/899685-20170112142603666-965135331.png)

- reactor模式

![img](https://images2017.cnblogs.com/blog/150046/201709/150046-20170901082644655-2144636819.png)

server导致阻塞的原因：

1、serversocket的accept方法，阻塞等待client连接，直到client连接成功。

2、线程从socket inputstream读入数据，会进入阻塞状态，直到全部数据读完。

3、线程向socket outputstream写入数据，会阻塞直到全部数据写完



**改进：采用基于事件驱动的设计，当有事件触发时，才会调用处理器进行数据处理**

![img](https://images2017.cnblogs.com/blog/150046/201709/150046-20170901082719280-29887948.png)

**改进：使用多线程处理业务逻辑。**

![img](https://images2017.cnblogs.com/blog/150046/201709/150046-20170901082834187-1581301551.png)

将处理器的执行放入线程池，多线程进行业务处理。但Reactor仍为单个线程。

**继续改进：对于多个CPU的机器，为充分利用系统资源，将Reactor拆分为两部分**

![img](https://images0.cnblogs.com/blog2015/434101/201503/112151380898648.jpg)

mainReactor负责监听连接，accept连接给subReactor处理，为什么要单独分一个Reactor来处理监听呢？因为像TCP这样需要经过3次握手才能建立连接，这个建立连接的过程也是要耗时间和资源的，单独分一个Reactor来处理，可以提高性能。

从结构上，这有点类似生产者消费者模式，即有一个或多个生产者将事件放入一个Queue中，而一个或多个消费者主动的从这个Queue中Poll事件来处理；而Reactor模式则并没有Queue来做缓冲，每当一个Event输入到Service Handler之后，该Service Handler会主动的根据不同的Event类型将其分发给对应的Request Handler来处理。



- socket 系统调用

创建socket 

int socket(int domain, int type, int protocal)

参数说明  第一个参数说明的是底层的协议  

第二个参数可以指定socket的类型  可以指定是 基于数据流的还是数据报的这就是tcp 还是udp的区分 其次还可以指定是非阻塞 或者是当进程进行fork调用的时候 该文件描述符 在子进程当中是关闭的。

第三个参数可以在第一个参数的条件下指定更具体的协议 但是一般前面已经可以确定  所以一般都是默认值 0  使用默认的协议。



以上只是说明的了socket的协议以及一些类型 但是没有绑定具体的地址：

- 命名socket

bind( int socketd , const struct sockaddr* my_addr, socklen_t addrlen)

将指定的地址分配各前面创建的socket 因为地址给的是指针 所以需要传递地址的长度 一面函数内部越界。

可能出现的错误：

1. 绑定知名端口 没有权限
2. 被绑定的端口正被使用 或者属于time_wait状态

- 监听端口

 socket被命名之后还需要 创建一个监听队列来存放待处理的客户连接：

int listen(int sockfd, int backlog)

第二个参数指定监听队列的长度 如果当前监听队列已满 则不再处理新的连接 将向客户端返回 连接拒绝的错误信息

- 接受连接

  int accept(int sockfd, struct sockaddr *addr,socklen_t * addrlen)

  传入的socket必须是已经调用过listen的，将从该文件描述符对应的内核监听队列当中取出一个远端连接的连接地址 放入参数指定的地址当中。返回一个

这个调用只是拿出连接 对网络状况毫不知情 如果在监听队列当中的客户端 断了还是怎么了 此时accept还是可以正常的拿出连接，对于客户端状况的判断需要上层传递数据之后才知道。



其实客户端就是上面这样的步骤，后序只要一个一个的accept得到对应的socket就好了，注意的是处理这些调用的一些错误。



- 发起连接

 int connect(int sockfd, const struct sockaddr *serv_addr, socklen_t addrlen)

常见的错误： 目标端口不存在  或者是连接超时 



- 关闭连接

int close(int fd)

只是将该文件描述符的引用计数减一  当引用计数为0的时候才真正关闭该文件描述符

fork的时候 如果文件描述符本身没有设定 fork的时候子进程当中是关闭的话 那么 子进程默认 将使得父进程的相应文件描述引用计数加一

int shutdown(int sockfd, int howto)

如果要立即关闭 使用shutdown 而且可以设定关闭的行为，是只关闭度还是写还是全部。



####  tcp数据读写

对于文件的读写操作 一样是可以使用在文件描述符上的。

但是socket本身还提供专门的读写操作：

recv 和 send







- dobbo 重试机制导致的雪崩

高并发下的大部分RT分布已经超过了你的Dubbo设置的超时时间

就是说由于服务器的响应变慢 整个RT的时间超过设置的超时时间，那么就会触发重试机制，那么就会造成新的请求，重试导致雪崩。RT响应时间。

- 可以关闭重试机制
- 重新评定超时时间





- 水仙花数

```c++
class Solution {
public:
    /**
     * @param n: The number of digits
     * @return: All narcissistic numbers with n digits
     */
    
    bool helper(int num,int n) {
        string s = to_string(num);
        int c = 0;
        for(int i=0;i<s.size();++i) {
            int cur = s[i] - '0';
            c += pow(cur,n);
        }
        return c == num;
    }
    
    vector<int> getNarcissisticNumbers(int n) {
        // write your code here
        int start = pow(10,n-1);
        int end = pow(10,n);
        
        vector<int> res;
        if(n==1)
            res.push_back(0);
        for(int i=start;i<end;++i) {
            if(helper(i,n))
                res.push_back(i);
        }
        return res;
    }
};
```

实现一个算法确定字符串中的字符是否均唯一出现

如果不使用额外的存储空间，你的算法该如何改变







- 阿里云计算平台 一面

算法题：反转一个句子当中的单词的顺序

问题：

1. C++使用的最多的数据结构
2. 使用vector存储数据你最多存储过多少个元素？
3. vector的内存是怎么管理的？底层的实现
4. 会自己定义类型对吧？如果使用空指针的话经常会core dump对吧？是不是空指针就没有办法调用类型上的函数了？
5. python的 __ new __ 方法知道是干什么的么？
6. python的元类使用过么？__ meta_class __ 使用过么？是解决什么问题的知道么？
7. unordered_map 和 map的区别
8. 使用的是c++的那个版本？
9. 问一个可能比较难的问题：如果c++ 当中判断一个类型有没有某个方法你有哪些方式可以做到？发散一下思维，这个问题可能比较难。
10. 说一下为什么选取openfaas？
11. 容器池的概念
12. 如果用户的执行代码只需要1-20ms 如果每次都起一个docker 那么延迟就比较高
13. 协程和线程的区别
14. 对于原来的实现，你有没有对比过两者的性能？
15. orm 框架给你带来的哪些的好处？
16. 在golang里面实现一个orm框架该怎么实现？
17. 短时间学习一个语言和做一个项目你会怎么做？
18. 设计接口是做了多少的工作量？
19. 了解过k8s，大概讲一下一个pod是怎么被创建出来，怎么被删除的？
20. websocket能做负载均衡么？



















#### c++ 总结

- 为什么C++调用空指针对象的成员函数可以运行通过？

这个问题很好，可以阐明“静态绑定”和“动态绑定”的区别。真正的原因是：因为对于非虚成员函数，Ｃ++这门语言是静态绑定的。对于C++。为了保证程序的运行时效率，Ｃ++的设计者认为凡是编译时能确定的事情，就不要拖到运行时再查找了。

实际对于非虚函数当中也没有对于成员的访问的情况就是可以不用在函数当中访问this指针此时编译器就不会把this指针和这个函数的调用绑定，就其实就是函数的直接调用，所以如果调用这个函数的指针是一个空指针是不会出问题的，因为是对于这种情况不是动态绑定的，不会在运行的时候去判断这个指针指向的对象是不是有这个方法。而是在编译的时候就知道不需要这个指针，所以不会出现任何的问题。

this指针：其实说是所有非类的成员函数的调用的时候应该都会有一个默认的参数就是this指针，所以其实都是编译器做的事情。但是如果是动态绑定才是在运行的时候通过this指针去找虚函数表的指针也就是在对象指针偏移的第一个位置，动态的通过指针的值去找虚函数表的指针，再去找到对应偏移的函数。为什么叫动态的绑定就是动态的找。但是静态绑定就不一样了，因为一切都是编译的时候确定的写死的，就是在这个位置调用这个函数就对了。

所以编译器在这个位置直接就写上这个函数入口就行了。其实这些查找的工作都是需要做的只是c++在编译的时候查，所以运行就效率高。

- core dump

core文件会包含了程序运行时的内存，寄存器状态，堆栈指针，内存管理信息还有各种函数调用堆栈信息等，我们可以理解为是程序工作当前状态存储生成第一个文件，许多的程序出错的时候都会产生一个core文件，通过工具分析这个文件，我们可以定位到程序异常退出的时候对应的堆栈调用等信息，找出问题所在并进行及时解决。

core文件默认的存储位置与对应的可执行程序在同一目录下，文件名是core

产生原因：

 1，内存访问越界

  a) 由于使用错误的下标，导致数组访问越界。

  b) 搜索字符串时，依靠字符串结束符来判断字符串是否结束，但是字符串没有正常的使用结束符。

 2，多线程程序使用了线程不安全的函数。

 3，多线程读写的数据未加锁保护

4，非法指针

  a) 使用空指针

  b) 随意使用指针转换。一个指向一段内存的指针，除非确定这段内存原先就分配为某种结构或类型，或者这种结构或类型的数组，否则不要将它转换为这种结构或类型的指针，而应该将这段内存拷贝到一个这种结构或类型中，再访问这个结构或类型。这是因为如果这段内存的开始地址不是按照这种结构或类型对齐的，那么访问它时就很容易因为bus error而core dump。

堆栈溢出

不要使用大的局部变量（因为局部变量都分配在栈上），这样容易造成堆栈溢出，破坏系统的栈和堆结构，导致出现[莫名其妙](https://www.baidu.com/s?wd=%E8%8E%AB%E5%90%8D%E5%85%B6%E5%A6%99&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)的错误。 

#### c++：如何判断类中是否存在特定的成员函数？

使用模板的高级特性，模板参数的自动推到和匹配。

模板函数可以根据参数自动推导出模板参数，进行替换。

那么函数的匹配的顺序？

在有多个函数和函数模板名字相同的情况下，一条函数调用语句到底应该被匹配成对哪个函数或哪个模板的调用呢？  编译器遵循以下先后顺序：

1. 先找参数完全匹配的普通函数（非由模板实例化得到的函数）。
2. 再找参数完全匹配的模板函数。
3. 再找实参经过自动类型转换后能够匹配的普通函数。
4. 如果上面的都找不到，则报错。

优先匹配非模板函数，然后匹配特化模板，然后匹配模板

模板函数而言是先特化在非特化。

- c++ RTTI功能
- 编译期能得到的 和 运行时能得到的

在C++里，可以在编译期计算表达式类型的只有下面两个东西：

**1. sizeof**
    这东西很强大，不论后面的表达式是什么，均可以在编译期正确得到类型并直接返回类型大小。

- typeof , typeid , decltype,auto

  这些东西的区别是什么？

  运行时类型鉴别RTTI 为什么需要运行时类型鉴别？有什么用？有什么问题？

  - 为了解决编译器做不到的事情，交给程序员去做
  - 使用父类指针或者引用指向的是子类的对象，此时想要调用子类定义的非虚函数，此时因为不是虚函数编译器帮不上忙，只能通过静态类型去判断，那么父类的静态类型必然没有这个函数，编译就会出错！切记是编译就会出错，编译的作用就是做好一切能够在编译时期确定的事情以及能够去检查到的错误。所以编译器不会知道他其实能够调用这个方法，因为静态类型才是编译器看的到的东西。所以会报错此时就需要RTTI去告诉编译器，把这个指针或者引用当做什么区看待，这样就可以让编译器通过检查，但是实际上这个玩意是不是你要转换的类型是你程序员去界定的，容易出错！

一个深入的问题：一段c++代码写出来，比如是逻辑判断，到底是在编译时期就知道结果还是运行时期才会知道结果？这会带来什么样的影响和问题？ 对于模板当中的判断是在编译的时候就知道的，对于其他的代码 其实看是什么了。

1.dynamic_cast 可以将基类或者父类的指针或者引用转换成派生类的指针或者引用 需要保证的是得有虚函数。当我们将dynamic_cast用于某种类型的指针或引用时，只有该类型含有虚函数时，才能进行这种转换。否则，编译器会报错。必须是含有虚函数才行。

这个当然是在运行时才会计算出结果，编译的时候是不知道被转换的指针实际指向的东西是不是含有虚函数的派生类对象，编译时期只能看到静态的东西。

2.typeid: 允许程序向表达式提问你的对象是什么类型？

如果该类型不属于类类型或者不包含任何的虚函数 那么结果是运算对象的静态类型 这就是编译器看到的类型

如果运算对象包含虚函数 那么typeid的结果直到运行时才会求得。这也很正确，因为如果是写在一个函数当中的时候，只有函数被调用的时候你才知道传入的参数是什么样的类型对吧。因为如果被运算的对象本身不是类类型或者没有虚函数那么实际其指向的对象可不可能包含虚函数也不会是需要动态的去绑定的东西，如果其静态类型是由虚函数的那么就有可能会出现需要动态绑定的东西所以就留到运行是计算结果。

如果在判断或者调用的时候是不需要用到这个指针指向的内容那么这个指针可以是空的只需要使用这个指针的静态类型就行了！这点是为了效率！为了编译器能够确定更多的东西。

- 模板的骚操作 Traits编程技法

  使用内嵌类型标识每个类型的某些特征，再使用模板参数的自动推导，然后在拿到类型之后萃取出相应名称的类型，就可以使用该类型。

  为什么要用这个骚操作？

  比如对于迭代器有多种类型，那么算法函数需要对这些不同的迭代器进行区分有的迭代器可以使用更有效的算法。

- 类模板函数模板是什么时候被实例化的？

  在我们使用类模板时，只有当代码中使用了类模板的一个实例的名字，而且上下文环境要求必须存在类的定义时，这个类模板才被实例化。

  　　1.1声明一个类模板的指针和引用，不会引起类模板的实例化，因为没有必要知道该类的定义。

  　　1.2定义一个类类型的对象时需要该类的定义，因此类模板会被实例化。

  　　1.3在使用sizeof()时，它是计算对象的大小，编译器必须根据类型将其实例化出来，所以类模板被实例化.

  　　1.4new表达式要求类模板被实例化。

  　　1.5引用类模板的成员会导致类模板被编译器实例化。

  　　1.6需要注意的是，类模板的成员函数本身也是一个模板。标准C++要求这样的成员函数只有在被调用或者取地址的时候，才被实例化。用来实例化成员函数的类型，就是其成员函数要调用的那个类对象的类型

- 编译器是怎么处理模板的？

 编译器遇到模板方法定义时，会进行语法检查，但是并不编译模板。编译器无法编译模板定义，因为它不知道使用什么类型。不知道x和y的类型，编译器就无法为x=y这样的语句生成代码。

#### 函数模板机制结论

1.编译器并不是把函数模板处理成能够处理任意类的函数

2.编译器从函数模板通过具体类型产生不同的函数

3.编译器会对函数模板进行**两次编译。**在声明的地方对模板代码本身进行编译；在调用的地方对参数替换后的代码进行编译。

就是说在写模板定义的地方会进行一次语法的编译，因为对于模板当中的模板参数，编译器是不知道这个类型是什么不知道这个类型有什么方法，是不是指针是不是可以解引用，这些编译器在定义处编译的时候都不知道，所以如果出了使用该类型本身定义变量之外的额外操作编译器都会报错！为什么编译器要这么做呢？

其次是在使用模板函数的时候根据传入的模板参数的类型实例化相应的模板类或者函数。这个时候也会编译。

所以说如果想用模板参数当中的类型做一些别的事情 那么就需要额外的工作。

模板的编译是有点意思的，你想直接使用模板参数的类型去定义的时候由于模板的编译是分两步的所以在写模板的时候是不知道模板参数对应的变量是什么的，所以是不能使用这个关于类型的性质的相关的性质的，但是使用这个模板类型是可以定义变量的，对于这个变量的相关操作是可以随意的这是不归编译器管的，就和定义函数一样传入的参数能不能做这样的操作或者调用相应的函数是会被编译器检查的但是模板当中大函数是不会的为什么？很简单因为模板在没有被实例化传参的时候是不知道函数的参数是什么类型的，这个时候编译器就是不知道这个类型的定义还怎么去检查这个函数内部对于这个相关对象的调用的合法？这个是保证不了的所以就由模板的定义者去保证，并且在实际的实例化的时候由于知道了实际的传入的模板参数此时实例化后的模板函数是会再次被编译器编译的此时编译器可以对函数内部的调用关系进行检查如果出现错误就报错。

所以 当你想使用模板参数做一些其他的工作的时候，比如你希望使用模板参数指定的类型的指针类型去定义变量此时一次的模板推导是不行的必须使用模板的嵌套，比如外层模板得到模板参数的对象，然后在该模板函数当中调用另一个模板函数，传入的是该变量的指针，因为有了这个变量取地址就得到其指针，但是我们没办法直接获取这个指针的类型进行使用，此时再传入模板函数就可以自动推导出这个指针的类型就在这个模板函数里面就可以获取这个指针的类型同时在这个函数内部就可以拿这个类型进行变量的定义。

模板参数的推导机制是不能推导函数的返回值的。

萃取使用的是结构体,通过在类当中内嵌定义内嵌类型的方式再通过这个结构体模板萃取出相应的内嵌类型。

对于原生指针可以特化。。。指针的特化可以在传入指针的时候提取出指针指向的类型本身。

典型的就是迭代器指向的类型的萃取需要统一所有的迭代器和原生指针：

```c++
template<typename Iterator>
struct iterator_traits
{
    typedef typename Iterator::value_type value_type;
};

//iterator_traits的偏特化版本，针对迭代器是个原生指针的情况
template<typename Iterator>
struct iterator_traits<Iterator*>
{
    typedef Iterator value_type;
};

```



- 对于模板需要知道的是什么？

 模板参数的自动推导

特化偏特化

编译阶段确定如果是某个特化类型，就用特化的模板

复用代码

保证 传递给模板参数的实参在模板内部满足要求的操作是调用者的责任不是编译器的责任。





#### 协程是怎么实现的？

因而下面我们来比较协程和线程。我们知道多个线程相对独立，有自己的上下文，切换受系统控制；而协程也相对独立，有自己的上下文，但是其切换由自己控制，由当前协程切换到其他协程由当前协程来控制。 
协程和线程区别：协程避免了无意义的调度，由此可以提高性能，但也因此，程序员必须自己承担调度的责任，同时，协程也失去了标准线程使用多CPU的能力。

线程的数量是有限制的但是你可以在一个线程里面轻松创建数十万个协程，就像数十万次函数调用一样

也就是说可以创建比线程多得多的协程。



协程之间是对称的平级的调用方式虽然协程类似函数 但是不是函数那样的上下级调用关系。

多线程在于线程之间对于共享的变量需要加锁，因为是来回切换的所以一份资源是被线程共享的也就是说谁都可能在操作的某一个阶段被调度到另一个线程去处理如果修改了资源的值那么这个线程再回来的时候。。不就是完了么？所以要加锁，其次就是线程是内核级线程的话，需要内核去调度，那么线程之间的切换是需要上下文的切换开销的。频繁的线程切换是会导致上下文的切换开销不可忽视！这是系统的性能瓶颈。

线程的切换你不知道是什么时候被切换！并且你只能在某些时候使用原子操作去保证某些代码在执行的时候是不可以被打断的，也就是不可以被cpu挂起去调度别的线程的，同时加锁其实就是这种不知道何时被切换的另一种代偿，因为不知道何时被切换所以就对资源加锁就好了，这样 就算我被切换出去了此时其他的线程在被调度的时候就算想访问我这个资源也是无效的操作拿不到锁就访问不了这个资源也就改变不了这个资源的状态，那么当我再被cpu调度的时候看到的资源没变，继续执行代码的逻辑就不会出错！这是加锁的核心！

我个人觉得这一切的导致都是内核在切换线程的不可判断性，你想如果内核能够智能的切换线程，那还需要加锁干嘛呢？但是就是会出现多个线程就是会同时想要对一个资源操作，为了提高响应才会使用多线程。这是多线程必须面对的问题。但是协程就不是了，用户去定义什么时候去切换不是内核，这个切换的开销比线程低得多，不用陷入内核，只是函数的切换开销级别，而且我自己定义切换就好办的多，不会出现对资源的同时同时竞争。也不需要加锁。这种协程间的调用是逻辑上可控的，时序上确定的，可谓一切尽在掌握中。

**如果将每个协程的上下文（比如程序计数器）保存在其它地方而不是堆栈上，协程之间相互调用时，被调用的协程只要从堆栈以外的地方恢复上次出让点之前的上下文即可，这有点类似于 CPU 的上下文切换**

就是说将协程栈保存在堆上而不是栈上！ 这是非常关键的其实和线程栈是分配在进程空间的堆空间时类似的吧！

协程是单线程环境，单线程当中的协程之间是不会冲突的 不存在竞争所以是不需要加锁的！！！每次都是只有一个协程在被当前的cpu执行！虽然失去了可以被调度调不同的cpu的能力但是没问题！这样就不需要加锁！。













- 文件的读和写  内核缓冲区和用户缓冲区 的概念的详细

read 的读入的过程是 先将文件读入内核缓冲区 再 将用户缓冲区的内容读入用户缓冲区 这样就是2次的操作 

多了一个将数据从内核缓冲区读入用户缓冲区的过程！ 

这样说就是 disk -> cache -> user 这个过程 

-  这下就出现新的问题  为什么要有内核缓冲区？

首先为什么要有告诉缓冲区？不直接访问 设备当中的数据你？ 这是因为IO设备和内存的读写速度的不匹配 如果有一点点数据要读或者写就访问磁盘那么导致的就是频繁的IO 效率很低。

那么就使用高速缓冲区  每次读数据先往高速缓冲区上去读 如果命中了那么就不需要IO了 如果没有再从磁盘上将指定的页读入缓冲区。

高速缓冲区在物理内存的位置是在内核区和主存之间。也就是内核模块->高速缓冲区->主存



这又来了问题 虽然大概是知道虚拟内存的布局但是 实际物理内存是怎么分布的？

内核空间是在哪？虚拟地址到物理地址的转换是怎么搞的？ 再看看吧！ 这些都是基本功 都是基础当中的基础 好好掌握 。

虚拟地址空间0~3G用于应用层 
虚拟地址空间3~4G用于内核层



![æ å°å³ç³"](https://images0.cnblogs.com/blog2015/687284/201506/041141519417456.jpg)



#### 内存管理的相关知识 了解了解总是OK的

1. Page Frame（页帧，或称页框）：是系统内存管理的最小单位，系统中每个页框都是struct page的一个实例。IA-32系统的页框大小是4KB 2.
2. Hot-n-Code Pages（冷热页）：是指内存管理中对页框的分类，访问较多的或者近期访问的为热页，否则为冷页。该标记主要与内存换出（memory swap）相关。
3. Page Table（页表）：是内存寻址过程中的辅助数据结构。层次化的页表对于大地之空间的快速、高效管理很有意义。Linux一般支持四级页表：PGD（Page Global Directory）、PUD（Page Upper Directory）、PMD（Page Middle Directory）和PTE（Page Table Entry）。IA-32体系中默认只是用了两级分页系统，即只有PGD和PTE。

**内核在内存中的布局**

在内核初始化的时候  会被加载到指定的内存的区域的固定的位置  这个位置是固定的 。

![11922142[4]](https://images0.cnblogs.com/blog/594483/201312/25195808-d7bfa210cc7142d3bbc73b23336cccee.png)



虚拟内存的布局：

常规情况下会将4GB线性空间划分成3:1的两部分：低地址的3/4部分为用户空间，而高地址的1GB是内核空间，即内核地址空间从偏移量0xC0000000开始 。每个虚拟地址x都对应于物理地址x-0xC0000000。这样的设计加快了内核空间寻址的速度（简单的减法操作）。在进程切换的过程中，只有用户空间的低3GB内存对应的页表会被切换，高地址空间会公用内核页表。



理解内核缓冲区技术的原理有助于更好的掌握系统调用read&write，**read把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区，它们不等价于数据在内核缓冲区和磁盘之间的交换**。

从理论上讲，内核可以在任何时候写磁盘，但并不是所有的write操作都会导致内核的写动作。内核会把要写的数据暂时存在缓冲区中，积累到一定数量后再一 次写入。有时会导致意外情况，比如断电，内核还来不及把内核缓冲区中的数据写道磁盘上，这些更新的数据就会丢失。
      应用内核缓冲技术导致的结果是：提高了磁盘的I/O效率；优化了磁盘的写操作；需要及时的将缓冲数据写到磁盘



也就是使用缓冲区的好处就是可以很好的进行集中写集中读的操作 减少对于磁盘的IO次数。

延后进行的写入操作并不会改变POSIX的语义。举例来说，数据刚写入缓冲区而尚未写回磁盘，此时如果发出读取请求，此请求可从缓冲区得到满足，而 且不会因此而读取到地盘上的旧数据。此行为会实际提高性能，因为读取请求可从内存中的缓冲区得到满足，而不必从磁盘。当读取和写入请求如预期般交替出现 时，结果也和预期一样，也就是说，数据被写回磁盘之前系统不会崩溃！即使应用程序相信写入请求已经成功完成了，但事实上数据尚未写回磁盘。

内核会试图尽量降低延后写入的风险，为了确保数据可以被及时写出，内核未缓冲区设立了一个时间上限，而且会在时间超过上限之前写出所有“脏”缓冲 区

肯定是有个定时器的 定时将缓冲区的内容写入 磁盘 。

是这样的 。。。。在读的时候 是会给出指定的地址和要读的长度的。。。也就是这个就是读的用户缓冲区！！！ 

ssize_t read(int fd, void * buf, size_t count);

救是这样啊   自己开一个空间就是一个buf将文件的指定的长度的数据读入这个buf当中 。

这个buf不就是 内存缓冲区么  简单明了 。

返回值：返回值为实际读取到的字节数, 如果返回0, 表示已到达文件尾或是无可读取的数据。若参数count 为0, 则read()不会有作用并返回0。

之后的上层程序都是读这个buf当中的数据  

用户缓冲区就是为了降低对于read系统调用的次数 每次多读一些 这样就减少系统调用的次数 减少 内核态和用户态的切换次数





#### 非阻塞socket的好处

 1.三次握手同时做其他的处理。connect要花一个往返时间完成，从几毫秒的局域网到几百毫秒或几秒的广域网。这段时间可能有一些其他的处理要执行，比如数据准备，预处理等。

2.如果使用非阻塞的connect，连接失败使用select等待很短时间，如果还没有连接后，线程立刻结束释放资源，防止大量线程阻塞而使程序崩溃。

非阻塞，就是进程或线程执行此函数时不必非要等待事件的发生，一旦执行肯定返回，以返回值的不同来反映函数的执行情况，如果事件发生则与阻塞方式相同，若事件没有发生则返回一个代码来告知事件未发生，而进程或线程继续执行，所以效率较高

因为如果事件发生了那么是和阻塞是一样的，主要就在这个没有发生的时候，如果事件没有发生：

阻塞调用会阻塞线程，非阻塞是不会阻塞线程的，可以根据返回值去做其他的事情 少一个阻塞线程切换线程的开销。

- 阻塞好控制，不发送完数据程序不会走下去。但是对性能有影响。
- 非阻塞不太好控制，可能和能力有关，但是性能会得到很大提升。
- 阻塞式的编程方便。
- 非阻塞的编程不方便，需要程序员处理各种返回值
- 阻塞处理简单，非阻塞处理复杂
- 阻塞效率低，非阻塞效率高

阻塞模式，常见的通信模型为多线程模型，服务端accept之后，对每个socket创建一个线程去recv。逻辑上简单，适用于并发量小，因为阻塞就是交出cpu切换线程调度 多线程的模型会好

非阻塞模式，常见的通信模型IO多路复用。适用于高并发，数据量小的情况，因为高并发情况下的多线程模型会降低效率，而IO多路复用是单线程的所以也不能一个调用就阻塞，所以是不能出现阻塞调用的。



的确非阻塞的情况使用的少的话就会比较容易模糊，所以一个是有时间多写写，其次记得就是非阻塞是根据调用返回值处理的所以逻辑上复杂。



#### 锁的几种概念清晰化

- 可重入锁
- 不可重入锁
- 自旋锁
- 互斥锁
- CAS 先对比再交换
- 乐观锁
- 悲观锁
- 大内核锁
- 读写锁 如何实现？

可不可重入的锁 是代码逻辑层面的概念，就是加锁之后会有一段代码时同步代码块 这段代码时一个临界区 同一个时间只有一个线程能够进入这个临界区。那么要进入临界区就要获得这个临界区的锁，出临界区就要释放这个临界区的锁。这之间的代码块就是所谓的临界区。还有一种情况就是全局锁只有一把，可以使用这个锁锁很多区域，如果已经获得这个锁之后需要进入另一个代码块，此时还需要获得这个锁一次，或者说这个函数还是被这个锁锁住那么如果是不可重入的锁那么就进不去了，也就是说锁本身的一个属性。关系到的是锁本身的抽象概念和使用方式。

那么一旦这个线程获取这个锁之后，没有释放这个锁，是否还可以再次进入这个临界区？这就是可重入锁和不可重入的区别。



#### 自旋锁？这个是形容这个锁本身的性质的！

CAS算法涉及到三个操作数

- 需要读写的内存值 V
- 进行比较的值 A
- 拟写入的新值 B

当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。

指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。

线程没有阻塞但是其实是在忙等待没做任何有效的事情。

问题：

1. 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。
2. 线程饥饿 

好处：就和非阻塞一样 

1. 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快
2. 非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）

就是说非阻塞的线程上下文切换的开销 自旋锁没有但是 自旋锁可能会有的就是 忙等待占用cpu看具体的业务场景使用？还是有额为的控制？

自旋锁就是适合短时间锁住的情况，长时间多线程的情况 请使用互斥锁！ 否则白白消耗CPU

所有锁的接口和库都是将锁当做一种 资源当资源可以用的时候会将阻塞在这个资源的线程唤醒这是这个锁本身需要提供的功能。

[Linux内核](https://www.baidu.com/s?wd=Linux%E5%86%85%E6%A0%B8&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)中，自旋锁是不可递归的。如果试图得到一个你正在持有的锁，你必须去自旋，等待你自己释放这个锁。但这时你处于自旋忙等待中，所以永远不会释放锁，就会造成死锁现象。



#### 互斥锁而言

如果没有获取是不会自旋的是会阻塞交出CPU 

#### 可重入和不可重入 

就是加上计数器

#### 信号量

PV操作。

P(sv)：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行

V(sv)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1.

这个回复被阻塞的进程这个是操作系统去做的，也就是没有必要去检查这个信号量的状态。



信号量和互斥锁之间的区别：

信号量时多线程之间同步的方式？ 互斥锁是线程之间实现互斥的方式；

信号量的概念是大于互斥锁的： 信号量可以做锁，锁住某段区域，进入值钱吗p出去之前v 这样保证其他线程进不来。这是对于某个资源而言，做保护，但是信号量还可以作为同步手段，A线程做了P操作，此时B需要在A执行一段什么逻辑之后再 执行自己的某个其他的逻辑，那就需要一个消息通信机制，那么可以使用信号量，当A 执行v操作之后，由于B也等待在这个信号量上，所以当A执行v的时候，B就会被唤醒，同步了。看问题的角度吧。

互斥锁是锁住某个资源为目的，对资源进行保护你可以使用这个资源进行同步就是了只不过2者再概念上是有细微的区别的。

**互斥量值只能为0/1，信号量值可以为非负整数。**



![img](https://img-blog.csdn.net/20180603183525863)

#### 大内核锁











#### 快手面试总结

 什么是RTT：

```
RTT——Round Trip Time，也就是一个数据包从发出去到回来的时间。
```

为什么需要RTT？

这是针对TCP而言的，因为这个时间的长短决定了TCP的超时重传的时间的设定！

重传的定时器的时间设定的早了就会导致过快重传！可能导致拥塞！

如果设置的时间长了就会导致 重发等待的时间过长！效率低下！

所以需要动态的设置这个时间。

```
设置Timeout——RTO（Retransmission TimeOut）
```

RTO重传时间 根据RTT设置RTO！

采用了抽样平滑移动等方式 使用了参数去动态的更新这个RTT和ROT保证稳定。

```
TCP通过一个timer采样了RTT并计算RTO
```





#### 流量控制

滑动窗口的理解：

解决什么问题？

可靠传输以及包的乱序到达的问题！ 网络永远都是不可靠的！

tcp需要知道网络实际的处理带宽和数据处理速度 

滑动窗口是用来做流量控制的！

tcp有一个字段叫做窗口大小字段，接收方可以通过ACK包当中设置这个字段的值告诉发送方我的接受缓冲区的大小还有多少，协调双发的收发速率。



链接：https://www.imooc.com/article/29368

来源：慕课网

![[éä¿ææ]æ·±å¥çè§£TCPåè®®ï¼ä¸ï¼ï¼RTTãæ"å¨çªå£ãæ¥å¡å¤ç_2.jpg](https://img2.mukewang.com/5afa496e00013ef709000358.jpg)



接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，我们可以看到中间有些数据还没有到达，所以有数据空白区。

发送端的LastByteAcked指向了被接收端Ack过的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有收到成功确认的Ack，LastByteWritten指向的是上层应用正在写的地方。

 各自都有三个指针 维护整个数据结构的稳定。



链接：https://www.imooc.com/article/29368

来源：慕课网



![[éä¿ææ]æ·±å¥çè§£TCPåè®®ï¼ä¸ï¼ï¼RTTãæ"å¨çªå£ãæ¥å¡å¤ç_3.png](https://img3.mukewang.com/5afa496f0001f0fa06600270.jpg)



**上图中分成了四个部分，分别是：（其中那个黑模型就是滑动窗口）**



- \#1 已收到ack确认的数据。
- \#2 发还没收到ack的。
- \#3 在窗口中还没有发出的（接收方还有空间）。
- \#4 窗口以外的数据（接收方没空间）

![[éä¿ææ]æ·±å¥çè§£TCPåè®®ï¼ä¸ï¼ï¼RTTãæ"å¨çªå£ãæ¥å¡å¤ç_1.png](https://img2.mukewang.com/5afa496f0001b34c06600210.jpg)





滑动窗口的大小就是决定了 发送方一次最多能够发生的数据的多少！！！！！

这是一个发送方和接收方相互协调的过程

![[éä¿ææ]æ·±å¥çè§£TCPåè®®ï¼ä¸ï¼ï¼RTTãæ"å¨çªå£ãæ¥å¡å¤ç_2.png](https://img.mukewang.com/5afa49700001db5306660836.jpg)

此时接收方的接受 缓冲区为0 此时发送方的发送窗口大小也为0 此时发送方式无法发送数据的，那么当接收方处理好数据之后发送方是怎么知道自己可以发了 ？？



```
解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。
```

```
只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。（
```

#### Silly Window Syndrome翻译成中文就是“糊涂窗口综合症”

  如果我们的接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送这几个字节。要知道，我们的TCP+IP头有40个字节，为了几个字节，要达上这么大的开销，这太不经济了。


```
另外，你需要知道网络上有个MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，这是因为 RFC 791里说了任何一个IP设备都得最少接收576尺寸的大小
```

```
如果你的网络包可以塞满MTU，那么你可以用满整个带宽，如果不能，那么你就会浪费带宽。（大于MTU的包有两种结局，一种是直接被丢了，另一种是会被重新分块打包发送） 你可以想像成一个MTU就相当于一个飞机的最多可以装的人，如果这飞机里满载的话，带宽最高，如果一个飞机只运一个人的话，无疑成本增加了，也而相当二。
```



要解决这个问题也不难，就是避免对小的window size做出响应，直到有足够大的window size再响应

两种解决办法：一个是接受段处理 直接返回ack0 一个是发送方处理使用Nagle算法



- 如果这个问题是由Receiver端引起的，那么就会使用 David D Clark’s 方案。在receiver端，如果收到的数据导致window size小于某个值，可以直接ack(0)回sender，这样就把window给关闭了，也阻止了sender再发数据过来，等到receiver端处理了一些数据后windows size 大于等于了MSS，或者，receiver buffer有一半为空，就可以把window打开让send 发送数据过来。
- 如果这个问题是由Sender端引起的，那么就会使用著名的 [Nagle’s algorithm](http://en.wikipedia.org/wiki/Nagle%27s_algorithm)。这个算法的思路也是延时处理，他有两个主要的条件：1）要等到 Window Size>=MSS 或是 Data Size >=MSS，2）收到之前发送数据的ack回包，他才会发数据，否则就是在攒数据。

```
另外，Nagle算法默认是打开的，所以，对于一些需要小包场景的程序——比如像telnet或ssh这样的交互性比较强的程序，你需要关闭这个算法。你可以在Socket设置TCP_NODELAY选项来关闭这个算法（关闭Nagle算法没有全局参数，需要根据每个应用自己的特点来关闭）
```

#### 拥塞控制

```
TCP的设计者觉得，一个伟大而牛逼的协议仅仅做到流控并不够，因为流控只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。
```

流量控制是网络层以上的事情 是传输层做的事情但是对整个网络并不可知。

如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。这是一个灾难。这是重传机制带来的问题！！！所以需要拥塞控制！！！！！ 经典！！！！！ 牛逼！！！！！ 

TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：TCP不是一个自私的协议，当拥塞发生的时候，**要做自我牺牲**。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。

**拥塞控制主要是四个算法：**

- 1）慢启动；
- 2）拥塞避免；
- 3）拥塞发生；
- 4）快速恢复。



### 1慢热启动算法 – Slow Start

首先，我们来看一下TCP的慢热启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来就像那些特权车一样霸道地把路占满。新同学上高速还是要慢一点，不要把已经在高速上的秩序给搞乱了

- 1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。
- 2）每当收到一个ACK，cwnd++; 呈线性上升
- 3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升
- 4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）

```
所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。
```

### 2拥塞避免算法 – Congestion Avoidance


前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：

- 1）收到一个ACK时，cwnd = cwnd + 1/cwnd

- 2）当每过一个RTT时，cwnd = cwnd + 1

  这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。



### 3拥塞状态时的算法


前面我们说过，当丢包的时候，会有以下两种情况。

**1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈：**

- sshthresh =  cwnd /2
- cwnd 重置为 1
- 进入慢启动过程

**2）Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时：**

- TCP Tahoe的实现和RTO超时一样。

- TCP Reno的实现是：

- - cwnd = cwnd /2
  - sshthresh = cwnd
  - 进入快速恢复算法——Fast Recovery

```
通过这种强烈地震荡快速而小心得找到网站流量的平衡点的
```



#### 4快速恢复算法 – Fast Recovery





#### SACK确认机制

SACK(Selective ACK)是TCP选项，它使得接收方能告诉发送方哪些报文段丢失，哪些报文段重传了，哪些报文段已经提前收到等信息。根据这些信息TCP就可以只重传哪些真正丢失的报文段。需要注意的是只有收到失序的分组时才会可能会发送SACK。

如果接受方收到的是乱序到达的数据包，那么确认的时候是确认连续到达的那一段数据，但是中间如果缺少那么发送方其实是不知道 具体未到达的是哪些包，会将所有发出但是未确认的包都重发，实际上只应该重发中间丢失的。

在一般的情况下：

**仅重传超时片段**：这是一种更加保守的方式，仅重传超时的片段，希望其他片段都能够成功接收。但因为发送端没法确认200后到底有多少片段没被接收，情况就比较复杂。如果该片段之后的其他片段实际上接收到了，这一方式是最佳的。如果没接收到，就无法正常执行，这时后面的每一个片段需要单独计时并重传。

**重传所有片段**：这是一种更激进或者说更悲观的方式。无论何时一个片段超时了，不仅重传该片段，还有所有其他尚未确认的片段（301-400和401-500都会重传）。这一方式确保了任何时间都有一个等待确认的停顿时间，在所有未确认片段丢失的情况下，会刷新全部未确认片段，以使对端设备多一次接收机会。这种方式的问题在于可能这些重传是不必要的。如果第一个片段丢失而后面其他片段都接收到了，也得重传所有片段。

原始的确认机制情况下： **TCP确认机制中，无法有效处理非连续TCP片段的问题。**

SACK机制可以解决这样的问题：

**但前提是连接的两方设备必须同时支持这一功能**，通过连接时使用的SYN片段来协商是否允许SACK（即抓包中显示的sackOK）。这一过程完成之后，任一设备都可以在常规TCP片段中使用SACK选项。这一选项包含一个关于已接收但未确认片段数据sequence number范围的列表，如果某个片段已被选择确认过，则该片段中的SACK比特位置为1。该方式使用激进方式的改进版本，一个片段重传之后，之后所有片段也会重传，**除非SACK比特位为1**

就是说接受方的ACK当中 会有一个字段表示当前哪些数据包是收到了但是没有返回ACK 发送方就可以重传的时候知道哪些可以不用再重传。这样就很好的协调双方。





#### 开机过程的简述 

-  BIOS 开机第一个启动的程序  是存储在ROM当中的层序是  放在只读内存当中的。

  就是基本输入输出系统

- 磁盘是这样基本的一个模式的：第一个扇区 是存放 主要的开机记录的  然后是分区表 

  分区表分为3个主分区 91个扩展分区  扩展分区可以再 分成逻辑分区、

- 开启的BIOS先读第一个扇区的主要的开机记录 。Master boot record, MBR

- 然后主要开机记录负责 执行其中的开机管理程序 这个程序就是一个自举程序将操作系统的核心文件加载



分区 和格式化 ： 对于分区的格式化是为了文件系统 一个分区一般只能格式化成一个文件系统。

- inode：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号；
- block：记录文件的内容，文件太大时，会占用多个 block。



文件是占用数据块的，一个文件可以占用多个数据块  是不是连续的呢？

- superblock：记录文件系统的整体信息，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等；
- block bitmap：记录 block 是否被使用的位域。



示意图

![img](https://cyc2018.github.io/CS-Notes/pics/BSD_disk.png)



几个典型的文件系统的名称和特色：

- EXT2

  以inode为基础的文件系统。

   文件系统一开始将inode与block规划好了，除非重新格式化，否则inode与block固定后就不再变动，但是当inode与block数量过多时，就不易于管理。因此Ext2在格式化的时候基本上是区分为多个块组（block group），每个块组都有独立的/inode/block/superblock系统

![img](https://images2017.cnblogs.com/blog/1270514/201712/1270514-20171209125950433-1759606881.png)

在整体的规划中，文件系统最前面有一个启动扇区(boot sector)，这个启动扇区可以安装引导装载程序。因此可以将不同的引导装在程序安装到个别的文件系统最前端，而不用覆盖整块硬盘唯一的MBR（主引导分区）

**data block （数据块）**：用来放置文件内容。在Ext2文件系统中所支持的block大小有1KB,2KB及4KB三种，在格式化block大小的时候就固定了，且每个block都有编号，以方便inode记录。

限制：

　　1)、原则上，block大小与数量在格式化完就不能再改变

　　2)、每个block内最多只能够放置一个文件的数据

　　3)、承上，如果文件大于block的大小，则一个文件会占用多个block数量

　　4)、承上，如果文件小于block，则该block的剩余空间就不能再被使用（磁盘空间会浪费）

**每个inode这么大的么？128字节？那个数是一开始就固定的！！ 那inode如果用完了是不是就分配不了文件描述符了？？？？**

**inodetable（inode表格）**：inode的内容主要记录文件的属性以及该文件实际数据是放置在哪几号block内，基本上，inode记录的文件数据至少有下面这些：

　　　　1)、该文件的访问模式

　　　　2)、该文件的所有者与组

　　　　3)、该文件的大小

　　　　4)、该文件创建或状态改变的时间

　　　　5)、最近一次的读取时间

　　　　6)、最近修改的时间

　　　　7)、定义文件特性的标志

　　　　8)、该文件真正内容的指向

　　　　9)、每个inode大小均固定在128bytes

　　　 10)、每个文件都仅会占用一个inode而已

　　　 11)、承上，因此文件系统能够创建的文件数量与inode的数量有关

　　　12)、系统读取文件时需要先找到inode，并分析inode所记录的权限与用户是否符合，若符合才能开始实际读取block的内容

每一个block是使用一个4个字节的数标识 那么INode就128个字节那么block如果很多的话 那一个inode是不是就存不下了？？？

所以iNode不是都直接记录这个block的编号的

- 直接寻址
- 间接寻址
- 双间接
- 三间接

1)、12个直接指向：12*1K=12K，由于是直接指向，所以总共可以记录12条记录

2)、间接：256*1K

　　　　每条block号码的记录会花去4bytes，因此1K的大小能记录256条记录

3)、双间接：256*256*1K=256^2K

4)、三间接：256*256*256*1K=256^3K

　　总额：将直接、间接、双间接、三间接加总，得到12+256+256^2+ 256^3=16GB，此时我们知道当文件系统将block格式化为为1K大小时，能够容纳的最大文件为16GB，比较一下文件系统线指标的结果可发现是一致的。但这个方法不能用在2K及4K的block大小的计算中。因为大于2K的block将会收到文件系统本身的限制

 

**Superblock(超级块)**

　　　　superblock是记录整个文件系统相关信息的地方，没有superblock，就没有这个文件系统了，它记录的主要信息有：

　　　　1)、block与inode的总量

　　　　2)、未使用与已使用的inode/block数量

　　　　3)、block与inode的大小

　　　　4)、文件系统的挂载时间、最近一次写入数据的时间、最近一次检验磁盘的时间等文件系统的相关信息

　　　　5)、一个validbit数值，若此文件系统已被挂载，则valid bit为0,若未被挂载，则valid bit为1



File System Description(文件系统描述说明)：这个区段可以描述每个block group的开始与结束的block号码，以及说明每个区段分别介于哪一个block号码之间

5、block bitmap(块对照表)：如果你想要添加文件时总会用到block。那你要使用哪个block来记录呢？当然是选择”空的block“来记录新文件的数据。那你怎么知道哪个block是空的？这就得通过

block bitmap 的辅助，从block bitmap 当中可以知道哪些block是空的，因此我们的系统就能很快速找到可使用的空间来处理文件。同样，如果删除某些文件时，那么哪些文件原本占用的block号码就得释放出来，此时在block bitmap当中相对应到该block号码的标志就得修改成为”未使用中“。这就是blockmap的功能。

inode bitmap(inode对照表)：这个与block bitmap功能类似，只是block bitmap记录的是使用与未使用的block号码，inode bitmap记录使用与未使用的inode号码。



也就是这些数据存储了整个文件系统的信息 ，文件系统的每个block 还是按照固定的大小来统一的管理这样的好处就是管理方便 大小非常好计算，问题就是会有利用效率的一些损失 但是没关系 。



对于目录而言：

录：当我们在Linux的ext2文件系统新建一个目录时，ext2会分配一个inode与至少一块block给该目录。其中inode记录该目录的相关权限与属性，并可记录分配的那块block号码。而block则是记录在这个目录下的文件名与该文件名占用的inode号码数据。

也就是一个目录也是一个文件，也占用一个inode但是只占用一个block

对于文件

文件：当我们在Linux下的ext2新建一个一般文件时，ext2会分配一个inode与相对于该文件大小的block数量给该文件



#### 我一直一来的疑问 linux是如何通过文件名最终找到文件的

open("/dev/tty1",O_RDWR,0);为例说一下:

a.首先看路径的首字符是不是/，判断是相对路径还是绝对路径，绝对路径是从root的inode开始找
b. 通过读root的inode的数据块(放在super_block中)，里面是一堆dir_entry,看有没有跟dev这个name字符串匹配的，
   若有则返回dev的inode_nr,即dir_entry中的inode_nr
c.有了dev的inode_nr，读取dev的inode
d.有了dev的inode就可以读取dev的数据块，因为dev是一个目录，再查找目录里面有没有跟tty1匹配的name字符串,
  若有则返回tty1的inode_nr,即dir_entry中的inode_nr
f. 有了tty1的inode_nr,就可以读取tty1中的数据，这儿是一个设备文件，只有一个设备号存在i_zone[0]中





#### 扇区：

文件储存在硬盘上，**硬盘的最小存储单位叫做”扇区“**（Sector，常见512B），**多个扇区组成的一个”块“**（block，常见4096B，即连续8个sector组成一个block）。操作系统一次性读取一个块（8个连续8个扇区），以提高磁盘IO效率。因此，**块是磁盘读写的最小单位**。

块是最小单位！  一次读4k 这是磁盘上的一块，那么内存的页也是4k一页，，有点东西的！









































最近概念：

- 多处理器缓存之间同步？ 系统总线内存流量问题？
- 基于链表的自旋锁？
- 公平性的可重入锁？
- 实现锁的方式？





